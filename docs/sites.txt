
:toc:

Turbine Sites Guide
===================
Justin M. Wozniak <wozniak@mcs.anl.gov>
v0.3.0, June 2013

////

This file is on the web at:

http://www.mcs.anl.gov/exm/local/guides/turbine-sites.html

////

== Overview

This manual provides a reference on how to run Swift/T Turbine
programs on a variety of systems.  It also contains an index of sites
maintained by the Swift/T team for use by Turbine.

For each machine, a *public installation* and/or a *build procedure* will
be provided.  The user need only follow one set of directions.

[[login_node]]
A *login node installation* may be available on certain systems.  This
will run Swift/T on the login node of that system.  This only acceptable for
short debugging runs of 1 minute or less.  It will affect other users
so please be cautious when using this mode for debugging.

=== Public installations

These are maintained by the Swift/T team.  Because they may become out
of date after a release, the release version and a timestamp are
recorded below.

To request maintenance on a public installation, simply email
exm-user@mcs.anl.gov .

=== Build procedures

To follow a build procedure, you may start with the +exm+ download
package.  Simply edit the +exm-setup+ script and modify the
configuration settings as described here.

=== Version numbers

The component version numbers that correspond together to make up a
Swift/T release may be found on the
link:../downloads/downloads.html[Downloads] page.

=== Freshness

These instructions may become stale for various reasons.  For example,
system administrators may update directory locations, breaking these
instructions.  Thus, we mark *As of:* dates on the instructions for
each system.

To report a problem, simply email exm-user@mcs.anl.gov .


=== For more information

* See the link:./stc.html[Swift/T Guide] for more information about Swift/T.
* Join the ExM (Swift/T project) http://lists.mcs.anl.gov/mailman/listinfo/exm-user[user mailing list].

== Turbine as MPI program

Turbine is a moderately complex MPI program.  It is essentially a Tcl
library that glues together multiple C-based systems, including MPI,
ADLB, and the Turbine dataflow library.

Running Turbine on a MPI-enabled system works as follows:

* Compilation and installation: This builds the Turbine libraries and
  links with the system-specific MPI library.  STC must also be
  informed of the Turbine installation to access correct built-in
  function information
* Run-time configuration: The startup job submission script locates
  the Turbine installation and reads configuration information
* Process launch: The Tcl shell, +tclsh+, is launched in parallel and
  configuration information is passed to it so it can find the
  libraries. The Tcl program script is the STC-generated user program
  file.  The MPI library enables communication among the +tclsh+
  processes.

Each of the systems below follows this basic outline.

On simpler systems, use the +turbine+ program.  This is a small shell
script wrapper that configures Turbine and essentially runs:
----
mpiexec tclsh program.tcl
----

On more complex, scheduled systems, users do not invoke +mpiexec+
directly.  Thus, sample scripts are provided below.

== x86 clusters

=== Generic clusters

This is the simplest method to run Turbine.

==== Build procedure

The +exm-setup.zsh+ script should just work.

To run, simply build a MPI hosts file and pass that to Turbine, which
will pass it to +mpiexec+.

----
turbine -l -n 3 -f hosts.txt program.tcl
----

=== MCS compute servers

Compute servers at MCS Division, ANL.
Operates as a generic cluster (see above).

----
echo crush.mcs.anl.gov >  hosts.txt
echo crank.mcs.anl.gov >> hosts.txt
turbine -l -n 3 -f hosts.txt program.tcl
----

=== Breadboard

Cf. link:http://wiki.mcs.anl.gov/radix/index.php/Breadboard[Breadboard Wiki]

Breadboard is a cloud-ish cluster for software development in
MCS. This is a fragile resource used by many MCS developers. Do not
overuse.

Operates as a generic cluster (see above).  No scheduler.  Once you
have the nodes, you can use them until you release them or time
expires (12 hours by default).

. Allocate nodes with +heckle+.  See Breadboard wiki
. Wait for nodes to boot
. Use +heckle allocate -w+ for better interaction
. Create MPICH hosts file:
+
----
heckle stat | grep $USER | cut -f 1 -d ' ' > hosts.txt
----
. Run:
+
----
export TURBINE_LAUNCH_OPTS='-f hosts.txt'
turbine -l -n 4 program.tcl
----
+
. Run as many jobs as desired on the allocation
. When done, release the allocation:
+
----
for h in $( cat hosts.txt )
do
  heckle free $h
done
----

=== Midway

Midway is a mid-sized SLURM cluster at the University of Chicago

==== Public installation

* Swift/T 0.2.1 - 02/11/2013
* STC: +~wozniak/Public/stc-0.0.3/bin/stc+

To run:

----
srun ~wozniak/Public/turbine-0.1.1/scripts/submit/slurm/turbine-slurm.sh -n 3 ~/program.tcl
----

==== Build procedure

* Midway uses OpenMPI.  We have tested with +/software/openmpi-1.6-el6-x86_64+
* Put +mpicc+ in your +PATH+
* Configure ADLB with:
+
----
CC=mpicc LDFLAGS="-Wl,-rpath -Wl,/software/openmpi-1.6-el6-x86_64/lib" --enable-mpi-2
----
* Configure Turbine with:
+
----
 --with-mpi-lib-name=mpi
----

=== Eureka

Eureka is a 100-node x86 cluster at the Argonne Leadership Computing
Facility (ALCF).  It uses the Cobalt scheduler.

==== Build procedure

* Configure Tcl and c-utils with gcc
* Configure ADLB with mpicc

To run:
----
export MODE=cluster
submit/cobalt/turbine-cobalt-run.zsh -n 3 ~/program.tcl
----

== Blue Gene

=== Blue Gene/P

==== Surveyor/Intrepid/Challenger

These machines are at the Argonne Leadership Computing Facility (ALCF).

===== Public installation

* Based on trunk
* STC: +~wozniak/Public/stc-trunk/bin/stc+

To run:

----
~wozniak/Public/turbine/scripts/submit/cobalt/turbine-cobalt-run.zsh -n 3 ~/program.tcl
----

===== Build procedure

To run on the <<login_node,login node>>:

* Install MPICH for the login nodes
* Configure Tcl and c-utils with gcc
* Configure ADLB with your MPICH
* Configure Turbine with
+
----
--enable-bgp LDFLAGS=-shared-libgcc
----
+
This makes adjustments for some Blue Gene quirks.

* Then, simply use the +bin/turbine+ program to run.  Be cautious in
  your use of the login nodes to avoid affecting other users.

_To run on the compute nodes under IBM CNK:_

In this mode, you cannot use +app+ functions to launch external
programs because CNK does not support this.  See ZeptoOS below.

* Configure Tcl with mpixlc
* Configure c-utils with gcc
* Configure ADLB with:
+
----
--enable-xlc
CC=/bgsys/drivers/ppcfloor/comm/bin/mpixlc
----
* Configure Turbine with:
+
----
CC=/soft/apps/gcc-4.3.2/gnu-linux/bin/powerpc-bgp-linux-gcc
--enable-custom
--with-mpi-include=/bgsys/drivers/V1R4M2_200_2010-100508P/ppc/comm/default/include
----

To run, use +scripts/submit/bgp/turbine-cobalt.zsh+
See the script header for usage.

_To run on the compute nodes under ZeptoOS:_

* Configure Tcl with zmpicc
* Configure c-utils with gcc
* Configure ADLB with
+
----
CC=zmpicc --enable-mpi-2
----
* Configure Turbine with
+
----
CC=/soft/apps/gcc-4.3.2/gnu-linux/bin/powerpc-bgp-linux-gcc
--enable-custom
--with-mpi-include=/bgsys/drivers/V1R4M2_200_2010-100508P/ppc/comm/default/include
----

To run, use +scripts/submit/bgp/turbine-cobalt.zsh+
See the script header for usage.

== Cray

=== Beagle

Beagle is a Cray XE6 at the University of Chicago

Remember that at run time, Beagle jobs can access only +/lustre+, not
NFS (including home directories).  Thus, you must install Turbine and
its libraries in +/lustre+.  Also, your data must be in +/lustre+.

==== Public installation

===== Login nodes

This installation is for use on the <<login_node,login node>>.

* Swift/T trunk - 6/11/2013
* Turbine: +~wozniak/Public/turbine-trunk-beagle-login+
* STC: +~wozniak/Public/stc-trunk-beagle-login+

===== Compute nodes

* Swift/T trunk - 6/11/2013
* Turbine: +/lustre/beagle/wozniak/Public/turbine+
* STC: +/lustre/beagle/wozniak/Public/stc+

To run:

1. Set environment variables.  The normal Turbine environment
variables are honored, plus the <<variables,Turbine scheduler
variables>>.
2. Run submit script (in +turbine/scripts/submit/cray+):
+
----
turbine-aprun-run.zsh script.tcl --arg1=value1 ...
----

==== Build procedure

Cray systems do not use +mpicc+.  We set +CC=gcc+ and use compiler
flags to configure the MPI library.

* Configure ADLB with:
+
----
./configure --prefix=/path/to/lb --with-c-utils=/path/to/c-utils
CC=gcc
CFLAGS=-I/opt/cray/mpt/default/gni/mpich2-gnu/47/include
LDFLAGS="-L/opt/cray/mpt/default/gni/mpich2-gnu/47/lib -lmpich"
--enable-mpi-2
----
+
* In the Turbine configure step, replace the +--with-mpi+ option with:
+
----
--enable-custom-mpi --with-mpi=/opt/cray/mpt/default/gni/mpich2-gnu/47
----

=== Raven

Raven is a Cray XE6/XK7 at Cray.

==== Build procedure

* Configure ADLB with:
+
----
./configure --prefix=/path/to/lb --with-c-utils=/path/to/c-utils
CC=gcc
CFLAGS=-I/opt/cray/mpt/default/gni/mpich2-gnu/46/include
LDFLAGS="-L/opt/cray/mpt/default/gni/mpich2-gnu/46/lib -lmpich"
--enable-mpi-2
----
+
* In the Turbine configure step, use:
+
----
--with-mpi=/opt/cray/mpt/default/gni/mpich2-gnu/46
----
* Use this Java when compiling/running STC: +/opt/java/jdk1.7.0_07/bin/java+

To run:

1. Set environment variables.  The normal Turbine environment
variables are honored, plus the <<variables,Turbine scheduler
variables>>.
2. Run submit script (in +turbine/scripts/submit/cray+):
+
----
turbine-aprun-run.zsh script.tcl --arg1=value1 ...
----

==== Advanced usage:

Turbine uses a PBS template file called
+turbine/scripts/submit/cray/turbine-aprun.sh.m4+.  This file is
simply filtered and submitted via +qsub+.  You can edit this file to
add additional settings as necessary.

==== Module:

You may load Swift/T with:

----
module use /home/users/p01577/Public/modules
module load swift-t
----

== Cloud

=== EC2

==== Setup

* Install http://instagram-engineering.tumblr.com/post/11399488246/simplifying-ec2-ssh-connections[+ec2-host+] on your local system
* Launch EC2 instances.
** Enable SSH among instances.
** Firewall settings must allow all all TCP/IP traffic for MPICH to run.
** If necessary, install Swift/T
** An AMI with Swift/T installed is available
* Use the provided script +turbine/scripts/submit/ec2/turbine-setup-ec2.zsh+.
** See the script header for usage notes
** This will configure SSH settings and create a hosts file for MPICH
   and install them on the EC2 instance

To run:
----
export TURBINE_LAUNCH_OPTS="-f $HOME/hosts.txt"
turbine program.tcl
----

[[variables]]
== Turbine scheduler variables

For scheduled systems, Turbine accepts a common set of environment
variables.

+NODES+:: Number of nodes to use
+PPN+:: Number of processes per node
+TURBINE_OUTPUT+:: Directory in which to place Turbine output
+QUEUE+:: Name of queue in which to run (may leave unset)

////
Local Variables:
mode: doc
eval: (auto-fill-mode 1)
End:
////
